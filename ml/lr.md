### 逻辑回归 

->梯度下降
	https://www.jianshu.com/p/c7e642877b0e

->参考：https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484011&idx=1&sn=42e4f331db843091c5c3809a4d259fad&chksm=970c2abda07ba3abb3963c2defcc644582f28bbdc23f3d669d022cd032e637d2ca8b6b48ca62&scene=21#wechat_redirect

->逻辑回归是一个线性分类器

### 卷积神经网络 CNN

-> 参考：https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484679&idx=1&sn=3684aa5a3379ecc3993be08c804d186b&chksm=970c2dd1a07ba4c7a145b3d0554cea6406b83cd282d98c9a68db7517e34d8ecebd3059a2f6fd&scene=21#wechat_redirect

-> 概述：
	一个卷积核 在每个位置处要同时考虑所有的channel-in；然后一个size的filter可以设置多个卷积核用于提取不同特征；然后可以设置不同size的多个filter来控制特征提取的粒度；然后可以设置多个输出通道channel-out表示多个分类任务。

### 循环神经网络 RNN

-> 参考：https://mp.weixin.qq.com/s?__biz=MzIwNzc2NTk0NQ==&mid=2247484682&idx=1&sn=51520138eed826ec891ac8154ee550f9&chksm=970c2ddca07ba4ca33ee14542cff0457601bb16236f8edc1ff0e617051d1f063354dda0f8893&scene=21#wechat_redirect

-> 概述：
	卷积神经网络CNN更关注局部特征的提取，加法更适合做信息叠加，乘法更适合做控制和扩容

### 长短时记忆神经网络 LSTM

-> 参考：https://zhuanlan.zhihu.com/p/30465140	
